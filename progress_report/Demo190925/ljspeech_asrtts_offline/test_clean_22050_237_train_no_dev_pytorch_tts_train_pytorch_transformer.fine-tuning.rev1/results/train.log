# Running on c11
# Started at Wed Sep 25 00:43:02 EDT 2019
# tts_train.py --backend pytorch --ngpu 1 --minibatches 0 --outdir exp/tts/test_clean_22050_237_train_no_dev_pytorch_tts_train_pytorch_transformer.fine-tuning.rev1/results --tensorboard-dir tensorboard/test_clean_22050_237_train_no_dev_pytorch_tts_train_pytorch_transformer.fine-tuning.rev1 --verbose 1 --seed 1 --resume --model exp/tts/test_clean_22050_237_train_no_dev_pytorch_tts_train_pytorch_transformer.fine-tuning.rev1/results/model.0th.copy --train-json dump/tts/test_clean_22050_237_train_no_dev/data.json --valid-json dump/tts/test_clean_22050_237_dev/data.json --config conf/tuning/tts_train_pytorch_transformer.fine-tuning.rev1.yaml 
free gpu: 3
/home/katsuki/tool/espnet/tools/venv/lib/python3.7/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
2019-09-25 00:43:12,221 (tts_train:170) INFO: ngpu: 1
2019-09-25 00:43:12,221 (tts_train:173) INFO: random seed = 1
2019-09-25 00:43:12,553 (deterministic_utils:24) INFO: torch type check is disabled
2019-09-25 00:43:12,653 (tts:273) INFO: #input dims : 35
2019-09-25 00:43:12,653 (tts:274) INFO: #output dims: 80
2019-09-25 00:43:12,654 (tts:291) INFO: writing a model config file toexp/tts/test_clean_22050_237_train_no_dev_pytorch_tts_train_pytorch_transformer.fine-tuning.rev1/results/model.json
2019-09-25 00:43:12,681 (tts:295) INFO: ARGS: accum_grad: 2
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: adim: 384
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: aheads: 4
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: backend: pytorch
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: batch_bins: 339600
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: batch_count: auto
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: batch_frames_in: 0
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: batch_frames_inout: 0
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: batch_frames_out: 0
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: batch_size: 0
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: batch_sort_key: input
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: bce_pos_weight: 5.0
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: config: conf/tuning/tts_train_pytorch_transformer.fine-tuning.rev1.yaml
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: config2: None
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: config3: None
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: debugmode: 1
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: decoder_concat_after: False
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: decoder_normalize_before: False
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: dlayers: 6
2019-09-25 00:43:12,682 (tts:295) INFO: ARGS: dprenet_dropout_rate: 0.5
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: dprenet_layers: 2
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: dprenet_units: 256
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: dunits: 1536
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: early_stop_criterion: validation/main/loss
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: elayers: 6
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: embed_dim: 0
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: encoder_concat_after: False
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: encoder_normalize_before: False
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: epochs: 20
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: eprenet_conv_chans: 0
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: eprenet_conv_filts: 0
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: eprenet_conv_layers: 0
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: eprenet_dropout_rate: 0.0
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: eps: 1e-06
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: eunits: 1536
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: grad_clip: 1.0
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: guided_attn_loss_lambda: 1.0
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: guided_attn_loss_sigma: 0.4
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: initial_decoder_alpha: 1.0
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: initial_encoder_alpha: 1.0
2019-09-25 00:43:12,683 (tts:295) INFO: ARGS: keep_all_data_on_mem: False
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: loss_type: L1
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: lr: 0.001
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: maxlen_in: 100
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: maxlen_out: 200
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: minibatches: 0
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: model: exp/tts/test_clean_22050_237_train_no_dev_pytorch_tts_train_pytorch_transformer.fine-tuning.rev1/results/model.0th.copy
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: model_module: espnet.nets.pytorch_backend.e2e_tts_transformer:Transformer
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: modules_applied_guided_attn: ['encoder-decoder']
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: ngpu: 1
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: num_heads_applied_guided_attn: 2
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: num_iter_processes: 0
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: num_layers_applied_guided_attn: 2
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: num_save_attention: 5
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: opt: noam
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: outdir: exp/tts/test_clean_22050_237_train_no_dev_pytorch_tts_train_pytorch_transformer.fine-tuning.rev1/results
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: patience: 0
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: postnet_chans: 256
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: postnet_dropout_rate: 0.5
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: postnet_filts: 5
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: postnet_layers: 5
2019-09-25 00:43:12,684 (tts:295) INFO: ARGS: preprocess_conf: None
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: reduction_factor: 1
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: report_interval_iters: 2
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: resume: None
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: save_interval_epochs: 1
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: seed: 1
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: sortagrad: 0
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: spc_dim: None
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: spk_embed_dim: None
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: spk_embed_integration_type: add
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: tensorboard_dir: tensorboard/test_clean_22050_237_train_no_dev_pytorch_tts_train_pytorch_transformer.fine-tuning.rev1
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: train_json: dump/tts/test_clean_22050_237_train_no_dev/data.json
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: transformer_dec_attn_dropout_rate: 0.1
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: transformer_dec_dropout_rate: 0.1
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: transformer_dec_positional_dropout_rate: 0.1
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: transformer_enc_attn_dropout_rate: 0.1
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: transformer_enc_dec_attn_dropout_rate: 0.1
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: transformer_enc_dropout_rate: 0.1
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: transformer_enc_positional_dropout_rate: 0.1
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: transformer_init: pytorch
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: transformer_lr: 1.0
2019-09-25 00:43:12,685 (tts:295) INFO: ARGS: transformer_warmup_steps: 4000
2019-09-25 00:43:12,686 (tts:295) INFO: ARGS: use_batch_norm: True
2019-09-25 00:43:12,686 (tts:295) INFO: ARGS: use_guided_attn_loss: True
2019-09-25 00:43:12,686 (tts:295) INFO: ARGS: use_masking: True
2019-09-25 00:43:12,686 (tts:295) INFO: ARGS: use_scaled_pos_enc: True
2019-09-25 00:43:12,686 (tts:295) INFO: ARGS: use_second_target: False
2019-09-25 00:43:12,686 (tts:295) INFO: ARGS: use_speaker_embedding: False
2019-09-25 00:43:12,686 (tts:295) INFO: ARGS: valid_json: dump/tts/test_clean_22050_237_dev/data.json
2019-09-25 00:43:12,686 (tts:295) INFO: ARGS: verbose: 1
2019-09-25 00:43:12,686 (tts:295) INFO: ARGS: weight_decay: 0.0
2019-09-25 00:43:13,164 (tts:301) INFO: Transformer(
  (encoder): Encoder(
    (embed): Sequential(
      (0): Embedding(35, 384, padding_idx=0)
      (1): ScaledPositionalEncoding(
        (dropout): Dropout(p=0.1)
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=384, out_features=1536, bias=True)
          (w_2): Linear(in_features=1536, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (norm1): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=384, out_features=1536, bias=True)
          (w_2): Linear(in_features=1536, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (norm1): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=384, out_features=1536, bias=True)
          (w_2): Linear(in_features=1536, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (norm1): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=384, out_features=1536, bias=True)
          (w_2): Linear(in_features=1536, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (norm1): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=384, out_features=1536, bias=True)
          (w_2): Linear(in_features=1536, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (norm1): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=384, out_features=1536, bias=True)
          (w_2): Linear(in_features=1536, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (norm1): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
  )
  (decoder): Decoder(
    (embed): Sequential(
      (0): Sequential(
        (0): Prenet(
          (prenet): ModuleList(
            (0): Sequential(
              (0): Linear(in_features=80, out_features=256, bias=True)
              (1): ReLU()
            )
            (1): Sequential(
              (0): Linear(in_features=256, out_features=256, bias=True)
              (1): ReLU()
            )
          )
        )
        (1): Linear(in_features=256, out_features=384, bias=True)
      )
      (1): ScaledPositionalEncoding(
        (dropout): Dropout(p=0.1)
      )
    )
    (decoders): MultiSequential(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=384, out_features=1536, bias=True)
          (w_2): Linear(in_features=1536, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (norm1): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=384, out_features=1536, bias=True)
          (w_2): Linear(in_features=1536, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (norm1): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=384, out_features=1536, bias=True)
          (w_2): Linear(in_features=1536, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (norm1): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=384, out_features=1536, bias=True)
          (w_2): Linear(in_features=1536, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (norm1): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=384, out_features=1536, bias=True)
          (w_2): Linear(in_features=1536, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (norm1): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=384, out_features=384, bias=True)
          (linear_k): Linear(in_features=384, out_features=384, bias=True)
          (linear_v): Linear(in_features=384, out_features=384, bias=True)
          (linear_out): Linear(in_features=384, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=384, out_features=1536, bias=True)
          (w_2): Linear(in_features=1536, out_features=384, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (norm1): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm(torch.Size([384]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
  )
  (feat_out): Linear(in_features=384, out_features=80, bias=True)
  (prob_out): Linear(in_features=384, out_features=1, bias=True)
  (postnet): Postnet(
    (postnet): ModuleList(
      (0): Sequential(
        (0): Conv1d(80, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Tanh()
        (3): Dropout(p=0.5)
      )
      (1): Sequential(
        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Tanh()
        (3): Dropout(p=0.5)
      )
      (2): Sequential(
        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Tanh()
        (3): Dropout(p=0.5)
      )
      (3): Sequential(
        (0): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Tanh()
        (3): Dropout(p=0.5)
      )
      (4): Sequential(
        (0): Conv1d(256, 80, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
        (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Dropout(p=0.5)
      )
    )
  )
  (criterion): TransformerLoss()
  (attn_criterion): GuidedMultiHeadAttentionLoss()
)
2019-09-25 00:43:13,166 (tts:314) INFO: reading model parameters from exp/tts/test_clean_22050_237_train_no_dev_pytorch_tts_train_pytorch_transformer.fine-tuning.rev1/results/model.0th.copy
2019-09-25 00:43:22,665 (batchfy:340) INFO: count is auto detected as bin
2019-09-25 00:43:22,666 (batchfy:359) INFO: # utts: 250
2019-09-25 00:43:22,666 (batchfy:92) INFO: # utts: 250
2019-09-25 00:43:22,667 (batchfy:138) INFO: 36 batches containing from 2 to 23 samples (avg 6 samples).
2019-09-25 00:43:22,667 (batchfy:396) INFO: # minibatches: 36
2019-09-25 00:43:22,667 (batchfy:340) INFO: count is auto detected as bin
2019-09-25 00:43:22,667 (batchfy:359) INFO: # utts: 14
2019-09-25 00:43:22,667 (batchfy:92) INFO: # utts: 14
2019-09-25 00:43:22,667 (batchfy:138) INFO: 3 batches containing from 3 to 8 samples (avg 4 samples).
2019-09-25 00:43:22,667 (batchfy:396) INFO: # minibatches: 3
epoch       iteration   elapsed_time  init_lr     lr          main/loss   validation/main/loss  main/l1_loss  validation/main/l1_loss  main/l2_loss  validation/main/l2_loss  main/bce_loss  validation/main/bce_loss  main/encoder_alpha  validation/main/encoder_alpha  main/decoder_alpha  validation/main/decoder_alpha  main/enc_dec_attn_loss  validation/main/enc_dec_attn_loss
[J0           2           2.6533        1           3.02577e-07  0.966736                          0.773213                               0.557867                               0.193523                                 1.45752                                            0.364641                                           0.00182699                                                 
[J0           4           3.65707       1           7.06013e-07  0.823918                          0.741345                               0.523693                               0.0825731                                1.45752                                            0.364641                                           0.00016704                                                 
[J0           6           4.62164       1           1.10945e-06  1.00069                           0.776281                               0.599562                               0.224413                                 1.45752                                            0.36464                                            0.000963028                                                
[J0           8           5.61172       1           1.51288e-06  0.823454                          0.750062                               0.546705                               0.0733923                                1.45752                                            0.364638                                           0.00025435                                                 
[J0           10          6.60135       1           1.91632e-06  0.784887                          0.727684                               0.514464                               0.0572033                                1.45751                                            0.364635                                           9.0035e-05                                                 
[J0           12          7.57019       1           2.31976e-06  0.796551                          0.732949                               0.519798                               0.0636024                                1.45751                                            0.364632                                           9.73258e-05                                                
[J0           14          8.53592       1           2.72319e-06  0.747322                          0.715065                               0.489775                               0.0322573                                1.45751                                            0.364628                                           0.000166754                                                
[J0           16          9.99917       1           3.12663e-06  0.759349                          0.729821                               0.506419                               0.0295285                                1.45751                                            0.364625                                           0.000229941                                                
[J1           18          148.255       1           3.53006e-06  0.736231    0.790776              0.69797       0.699015                 0.474859      0.472556                 0.0382612      0.0917611                 1.45751             1.4575                         0.364622            0.364619                       6.83944e-05             0.00046309                         
[J1           20          153.271       1           3.9335e-06  0.858017                          0.72592                                0.520103                               0.132097                                 1.4575                                             0.364618                                           0.000377487                                                
[J1           22          154.02        1           4.33693e-06  0.798308                          0.726263                               0.510008                               0.0720453                                1.4575                                             0.364614                                           0.000253002                                                
[J1           24          154.83        1           4.74037e-06  0.786679                          0.714343                               0.493101                               0.0723353                                1.4575                                             0.36461                                            0.00026483                                                 
[J1           26          155.651       1           5.14381e-06  0.715086                          0.681198                               0.457052                               0.0338884                                1.4575                                             0.364604                                           8.35785e-05                                                
[J1           28          156.435       1           5.54724e-06  0.758003                          0.694722                               0.476016                               0.0632808                                1.4575                                             0.364596                                           0.000154686                                                
[J1           30          157.26        1           5.95068e-06  0.737657                          0.681489                               0.438307                               0.0561677                                1.4575                                             0.364587                                           0.000156535                                                
[J1           32          158.051       1           6.35411e-06  0.785684                          0.690323                               0.472127                               0.0953618                                1.45749                                            0.364577                                           0.00045675                                                 
[J1           34          158.884       1           6.75755e-06  0.743635                          0.679176                               0.456284                               0.0644594                                1.45749                                            0.364566                                           0.000151487                                                
[J2           36          290.171       1           7.16098e-06  0.722317    0.735106              0.69456       0.646904                 0.464238      0.411822                 0.0277575      0.0882019                 1.45749             1.45748                        0.364555            0.364547                       0.000174517             0.00054052                         
[J2           38          295.17        1           7.56442e-06  0.922131                          0.77475                                0.591405                               0.14738                                  1.45748                                            0.364545                                           0.0135903                                                  
[J2           40          295.992       1           7.96786e-06  0.734032                          0.668729                               0.448737                               0.0653039                                1.45748                                            0.364535                                           0.000335967                                                
[J2           42          296.866       1           8.37129e-06  0.655801                          0.640477                               0.402634                               0.0153241                                1.45748                                            0.364523                                           0.000106096                                                
[J2           44          297.66        1           8.77473e-06  0.743723                          0.665587                               0.43443                                0.0781359                                1.45747                                            0.364509                                           0.000494611                                                
[J2           46          298.458       1           9.17816e-06  0.700192                          0.651051                               0.413434                               0.0491411                                1.45746                                            0.364494                                           0.000203319                                                
[J2           48          299.333       1           9.5816e-06  0.759429                          0.658494                               0.436938                               0.100935                                 1.45745                                            0.364477                                           0.000763748                                                
[J2           50          300.178       1           9.98504e-06  0.648956                          0.629332                               0.389094                               0.0196243                                1.45744                                            0.364458                                           0.000209226                                                
[J2           52          300.929       1           1.03885e-05  0.650614                          0.617306                               0.37279                                0.0333075                                1.45744                                            0.364442                                           0.000166186                                                
[J3           54          436.904       1           1.07919e-05  0.649365    0.650048              0.614889      0.586087                 0.372833      0.348896                 0.0344762      0.0639604                 1.45743             1.45742                        0.364424            0.36441                        0.000153806             0.000643972                        
[J3           56          442.076       1           1.11953e-05  0.663291                          0.614432                               0.373486                               0.0488585                                1.45742                                            0.364406                                           0.000226324                                                
[J3           58          442.941       1           1.15988e-05  0.644037                          0.605798                               0.355861                               0.0382389                                1.45741                                            0.36439                                            0.000195102                                                
[J3           60          443.841       1           1.20022e-05  0.717008                          0.645229                               0.420837                               0.0717794                                1.4574                                             0.364372                                           0.000844946                                                
[J3           62          444.635       1           1.24056e-05  0.669326                          0.612299                               0.379448                               0.0570274                                1.45738                                            0.364354                                           0.000348518                                                
[J3           64          445.422       1           1.28091e-05  0.642889                          0.607673                               0.370314                               0.0352158                                1.45737                                            0.364335                                           0.000209703                                                
[J3           66          446.319       1           1.32125e-05  0.63106                           0.613498                               0.36773                                0.0175618                                1.45736                                            0.364314                                           0.0002636                                                  
[J3           68          447.051       1           1.3616e-05  0.904854                          0.738911                               0.559701                               0.165943                                 1.45735                                            0.364294                                           0.0138713                                                  
[J3           70          447.897       1           1.40194e-05  0.609169                          0.586188                               0.343808                               0.0229818                                1.45735                                            0.364273                                           0.000120194                                                
[J4           72          584.084       1           1.44228e-05  0.591072    0.599287              0.570037      0.553353                 0.316952      0.310762                 0.0210354      0.0459349                 1.45734             1.45734                        0.364253            0.364241                       0.000186272             0.000710209                        
[J4           74          589.624       1           1.48263e-05  0.624122                          0.59164                                0.351558                               0.0324822                                1.45734                                            0.364237                                           0.0003346                                                  
[J4           76          590.496       1           1.52297e-05  0.684965                          0.611178                               0.37007                                0.0737875                                1.45734                                            0.364223                                           0.0019008                                                  
[J4           78          591.292       1           1.56331e-05  0.593921                          0.575925                               0.325918                               0.0179966                                1.45734                                            0.364208                                           0.000134911                                                
[J4           80          592.12        1           1.60366e-05  0.612631                          0.592551                               0.344745                               0.0200798                                1.45733                                            0.364197                                           0.000284039                                                
[J4           82          592.952       1           1.644e-05   0.607644                          0.583613                               0.336843                               0.024031                                 1.45733                                            0.364189                                           0.000295162                                                
[J4           84          593.732       1           1.68434e-05  0.578162                          0.558439                               0.310577                               0.0197229                                1.45733                                            0.364185                                           0.000302894                                                
[J4           86          594.443       1           1.72469e-05  0.644969                          0.586094                               0.343833                               0.0588755                                1.45733                                            0.364181                                           0.000836972                                                
[J4           88          595.202       1           1.76503e-05  0.608422                          0.583042                               0.336869                               0.0253803                                1.45733                                            0.364177                                           0.000386396                                                
[J5           90          729.459       1           1.80538e-05  0.619357    0.573558              0.566962      0.531643                 0.321742      0.286533                 0.0523945      0.0419151                 1.45733             1.45734                        0.364175            0.364174                       0.000563423             0.00070628                         
[J5           92          734.53        1           1.84572e-05  0.594472                          0.566294                               0.317381                               0.0281783                                1.45734                                            0.364173                                           0.000288162                                                
[J5           94          735.353       1           1.88606e-05  0.682191                          0.620984                               0.403059                               0.0612075                                1.45735                                            0.364171                                           0.0105697                                                  
[J5           96          736.231       1           1.92641e-05  0.578695                          0.558242                               0.310592                               0.0204526                                1.45735                                            0.364173                                           0.00018605                                                 
[J5           98          737.174       1           1.96675e-05  0.572169                          0.55101                                0.298826                               0.0211592                                1.45736                                            0.364175                                           0.000306259                                                
[J5           100         738.041       1           2.00709e-05  0.574005                          0.553761                               0.305275                               0.0202441                                1.45737                                            0.364179                                           0.000158329                                                
[J     total [#############.....................................] 27.78%
this epoch [###########################.......................] 55.56%
       100 iter, 5 epoch / 20 epochs
       inf iters/sec. Estimated time to finish: 0:00:00.
[4A[J5           102         738.796       1           2.04744e-05  0.663139                          0.5869                                 0.34458                                0.0762386                                1.45738                                            0.364181                                           0.00218086                                                 
[J5           104         739.574       1           2.08778e-05  0.558803                          0.539094                               0.285881                               0.0197087                                1.45739                                            0.364182                                           0.000164051                                                
[J5           106         740.401       1           2.12812e-05  0.578519                          0.55775                                0.30505                                0.0207689                                1.45739                                            0.364184                                           0.000246305                                                
[J6           108         875.308       1           2.16847e-05  0.567109    0.546913              0.547809      0.510861                 0.297023      0.26193                  0.0193004      0.0360524                 1.45739             1.45739                        0.364188            0.364192                       9.82791e-05             0.000711803                        
[J6           110         880.783       1           2.20881e-05  0.580313                          0.550269                               0.300754                               0.0300432                                1.45739                                            0.364193                                           0.00031957                                                 
[J6           112         881.522       1           2.24915e-05  0.624768                          0.563003                               0.313076                               0.0617651                                1.45738                                            0.364201                                           0.00184836                                                 
[J6           114         882.342       1           2.2895e-05  0.565858                          0.550578                               0.302442                               0.0152793                                1.45738                                            0.364205                                           0.00024984                                                 
[J6           116         883.025       1           2.32984e-05  0.571136                          0.539187                               0.287446                               0.0319492                                1.45739                                            0.36421                                            0.000323445                                                
[J6           118         883.767       1           2.37019e-05  0.565009                          0.538716                               0.283233                               0.0262927                                1.45739                                            0.364212                                           0.000169428                                                
[J6           120         884.615       1           2.41053e-05  0.557374                          0.528759                               0.274167                               0.0286145                                1.45739                                            0.364212                                           0.000230041                                                
[J6           122         885.407       1           2.45087e-05  0.543439                          0.522555                               0.268343                               0.0208837                                1.45738                                            0.36422                                            0.00014393                                                 
[J6           124         886.294       1           2.49122e-05  0.565299                          0.55188                                0.297424                               0.0134191                                1.45737                                            0.36423                                            0.000245866                                                
[J7           126         1021.61       1           2.53156e-05  0.602623    0.525015              0.549231      0.494079                 0.300976      0.243691                 0.0533919      0.0309366                 1.45737             1.45738                        0.364238            0.36424                        0.000721269             0.000678089                        
[J7           128         1027.01       1           2.5719e-05  0.559387                          0.536657                               0.285779                               0.0227308                                1.45738                                            0.364241                                           0.000188489                                                
[J7           130         1027.81       1           2.61225e-05  0.536207                          0.523106                               0.26883                                0.0131011                                1.45738                                            0.364239                                           0.000100153                                                
[J7           132         1028.58       1           2.65259e-05  0.552324                          0.52971                                0.274071                               0.0226142                                1.45738                                            0.364238                                           0.000180212                                                
[J7           134         1029.64       1           2.69293e-05  0.533735                          0.515078                               0.257807                               0.0186575                                1.45737                                            0.364241                                           0.000144765                                                
[J7           136         1030.47       1           2.73328e-05  0.548193                          0.528637                               0.274649                               0.0195555                                1.45736                                            0.364253                                           0.000216352                                                
[J7           138         1031.49       1           2.77362e-05  0.529497                          0.516386                               0.259638                               0.0131103                                1.45735                                            0.364271                                           8.65297e-05                                                
[J7           140         1032.34       1           2.81396e-05  0.544253                          0.517791                               0.261145                               0.0264618                                1.45734                                            0.36429                                            0.000199888                                                
[J7           142         1033.24       1           2.85431e-05  0.544031                          0.523477                               0.270459                               0.0205542                                1.45734                                            0.364306                                           0.000152179                                                
[J8           144         1169.9        1           2.89465e-05  0.584958    0.51991               0.535444      0.48229                  0.282087      0.232913                 0.0495141      0.0376203                 1.45735             1.45735                        0.364324            0.364337                       0.00182504              0.000742406                        
[J8           146         1175.59       1           2.935e-05   0.547783                          0.531489                               0.281755                               0.0162931                                1.45736                                            0.364341                                           0.000238638                                                
[J8           148         1176.41       1           2.97534e-05  0.533037                          0.520217                               0.267244                               0.01282                                  1.45739                                            0.364359                                           0.000185289                                                
[J8           150         1177.23       1           3.01568e-05  0.530538                          0.514273                               0.257592                               0.0162644                                1.4574                                             0.364379                                           9.26754e-05                                                
[J8           152         1178.08       1           3.05603e-05  0.512845                          0.501245                               0.245059                               0.0116001                                1.45741                                            0.364402                                           9.404e-05                                                  
[J8           154         1178.93       1           3.09637e-05  0.553317                          0.521789                               0.266528                               0.0315283                                1.45741                                            0.364419                                           0.000331099                                                
[J8           156         1179.82       1           3.13671e-05  0.535263                          0.512818                               0.260365                               0.0224447                                1.45742                                            0.364422                                           0.00014092                                                 
[J8           158         1180.77       1           3.17706e-05  0.523957                          0.507077                               0.251481                               0.0168807                                1.45743                                            0.364419                                           8.96564e-05                                                
[J8           160         1181.58       1           3.2174e-05  0.514236                          0.49852                                0.245303                               0.0157163                                1.45745                                            0.364417                                           0.000244427                                                
[J9           162         1316.97       1           3.25774e-05  0.538986    0.505899              0.527432      0.472357                 0.271823      0.223739                 0.0115543      0.033542                  1.45747             1.45749                        0.364414            0.364416                       0.000235338             0.00074694                         
[J9           164         1322.23       1           3.29809e-05  0.524782                          0.506896                               0.255507                               0.017886                                 1.45749                                            0.364417                                           0.000156385                                                
[J9           166         1323.12       1           3.33843e-05  0.516874                          0.503609                               0.246144                               0.0132654                                1.45751                                            0.364424                                           0.00010085                                                 
[J9           168         1324.06       1           3.37877e-05  0.505435                          0.494693                               0.23992                                0.0107415                                1.45753                                            0.364432                                           0.000115475                                                
[J9           170         1325.04       1           3.41912e-05  0.539653                          0.521196                               0.266755                               0.0184577                                1.45756                                            0.364437                                           0.000263921                                                
[J9           172         1325.92       1           3.45946e-05  0.534985                          0.509954                               0.258541                               0.0250317                                1.45758                                            0.364442                                           0.000296003                                                
[J9           174         1326.79       1           3.49981e-05  0.527887                          0.51372                                0.263394                               0.0141664                                1.4576                                             0.364451                                           0.000204555                                                
[J9           176         1327.57       1           3.54015e-05  0.535911                          0.505619                               0.254348                               0.0302916                                1.45762                                            0.36447                                            0.000498058                                                
[J9           178         1328.28       1           3.58049e-05  0.51723                           0.492491                               0.239854                               0.0247394                                1.45763                                            0.364489                                           0.000295168                                                
[J10          180         1463.68       1           3.62084e-05  0.520269    0.497252              0.498422      0.463079                 0.246249      0.215284                 0.0218474      0.0341724                 1.45764             1.45765                        0.364497            0.364496                       0.000155325             0.00071843                         
[J10          182         1468.99       1           3.66118e-05  0.624774                          0.544255                               0.308329                               0.0805193                                1.45765                                            0.364495                                           0.0135194                                                  
[J10          184         1469.85       1           3.70152e-05  0.541252                          0.517219                               0.27049                                0.0240328                                1.45765                                            0.364485                                           0.000416211                                                
[J10          186         1470.66       1           3.74187e-05  0.501958                          0.488453                               0.232213                               0.0135046                                1.45764                                            0.36448                                            9.41353e-05                                                
[J10          188         1471.66       1           3.78221e-05  0.499694                          0.488071                               0.234128                               0.0116228                                1.45764                                            0.364482                                           8.77506e-05                                                
[J10          190         1472.35       1           3.82255e-05  0.501465                          0.487614                               0.235539                               0.0138505                                1.45764                                            0.364495                                           6.88213e-05                                                
[J10          192         1473.17       1           3.8629e-05  0.555055                          0.512973                               0.263049                               0.0420822                                1.45764                                            0.364498                                           0.00172656                                                 
[J10          194         1474.01       1           3.90324e-05  0.495723                          0.483447                               0.231396                               0.0122753                                1.45765                                            0.364492                                           6.09365e-05                                                
[J10          196         1474.78       1           3.94358e-05  0.50942                           0.495799                               0.245456                               0.0136211                                1.45766                                            0.364492                                           0.000308565                                                
[J11          198         1609.03       1           3.98393e-05  0.504182    0.49924               0.485767      0.460199                 0.233425      0.213338                 0.0184141      0.0390415                 1.45767             1.45768                        0.364508            0.364527                       0.000122797             0.000812565                        
[J11          200         1612.99       1           4.02427e-05  0.518017                          0.493221                               0.24158                                0.0247958                                1.45768                                            0.364533                                           0.000230643                                                
[J     total [###########################.......................] 55.56%
this epoch [#####.............................................] 11.11%
       200 iter, 11 epoch / 20 epochs
   0.11429 iters/sec. Estimated time to finish: 0:23:19.926067.
[4A[J11          202         1613.89       1           4.06462e-05  0.513063                          0.492307                               0.242237                               0.0207562                                1.45769                                            0.364556                                           0.000184678                                                
[J11          204         1614.7        1           4.10496e-05  0.484745                          0.473164                               0.220458                               0.0115803                                1.4577                                             0.364565                                           9.26522e-05                                                
[J11          206         1615.48       1           4.1453e-05  0.508636                          0.483442                               0.230017                               0.0251941                                1.4577                                             0.364561                                           0.000441394                                                
[J11          208         1616.29       1           4.18565e-05  0.526831                          0.493528                               0.239528                               0.0333027                                1.45772                                            0.364558                                           0.000593827                                                
[J11          210         1617.16       1           4.22599e-05  0.508767                          0.495741                               0.247435                               0.0130257                                1.45774                                            0.364562                                           0.0001982                                                  
[J11          212         1617.92       1           4.26633e-05  0.537088                          0.498878                               0.247525                               0.0382107                                1.45775                                            0.364578                                           0.00159942                                                 
[J11          214         1618.79       1           4.30668e-05  0.491041                          0.482121                               0.226847                               0.00892051                               1.45774                                            0.364601                                           8.01164e-05                                                
[J12          216         1752.04       1           4.34702e-05  0.498242    0.476665              0.478604      0.449484                 0.225256      0.204177                 0.0196387      0.0271808                 1.45773             1.45772                        0.364609            0.364607                       0.000285295             0.000661652                        
[J12          218         1757.24       1           4.38736e-05  0.478698                          0.470758                               0.21493                                0.00794054                               1.45772                                            0.364607                                           8.39321e-05                                                
[J12          220         1757.99       1           4.42771e-05  0.479036                          0.46975                                0.21834                                0.00928583                               1.45772                                            0.364607                                           6.9122e-05                                                 
[J12          222         1758.66       1           4.46805e-05  0.5228                            0.485325                               0.234079                               0.0374754                                1.45772                                            0.3646                                             0.00161486                                                 
[J12          224         1759.48       1           4.50839e-05  0.496082                          0.484612                               0.233946                               0.0114697                                1.45772                                            0.36459                                            0.000127185                                                
[J12          226         1760.29       1           4.54874e-05  0.499163                          0.481005                               0.230256                               0.0181583                                1.45773                                            0.364591                                           0.00025764                                                 
[J12          228         1761.1        1           4.58908e-05  0.537849                          0.504498                               0.258807                               0.0333515                                1.45775                                            0.364605                                           0.00070782                                                 
[J12          230         1762.05       1           4.62943e-05  0.508958                          0.484524                               0.230774                               0.0244337                                1.45777                                            0.36462                                            0.000309302                                                
[J12          232         1762.87       1           4.66977e-05  0.485001                          0.470576                               0.217457                               0.0144247                                1.45778                                            0.36464                                            0.000115777                                                
[J13          234         1898.69       1           4.71011e-05  0.481625    0.472663              0.472458      0.446438                 0.220562      0.20245                  0.00916708     0.0262244                 1.45778             1.45779                        0.364672            0.364693                       5.63387e-05             0.000651864                        
[J13          236         1903.78       1           4.75046e-05  0.511619                          0.48047                                0.228197                               0.0311494                                1.45779                                            0.364697                                           0.000561866                                                
[J13          238         1904.52       1           4.7908e-05  0.50837                           0.480315                               0.230355                               0.0280542                                1.45781                                            0.364701                                           0.000281049                                                
[J13          240         1905.3        1           4.83114e-05  0.503669                          0.475632                               0.225983                               0.0280373                                1.45783                                            0.364706                                           0.000477349                                                
[J13          242         1906.11       1           4.87149e-05  0.522455                          0.48749                                0.236071                               0.0349644                                1.45786                                            0.364731                                           0.00160871                                                 
[J13          244         1906.84       1           4.91183e-05  0.474711                          0.461175                               0.207539                               0.0135358                                1.45789                                            0.364767                                           9.03231e-05                                                
[J13          246         1907.66       1           4.95217e-05  0.476068                          0.467242                               0.217686                               0.00882584                               1.45791                                            0.364794                                           5.76176e-05                                                
[J13          248         1908.47       1           4.99252e-05  0.498545                          0.482629                               0.234548                               0.015916                                 1.45793                                            0.364818                                           0.00023429                                                 
[J13          250         1909.34       1           5.03286e-05  0.516225                          0.503068                               0.254313                               0.013157                                 1.45797                                            0.364841                                           0.000260766                                                
[J14          252         2045.37       1           5.0732e-05  0.647245    0.476989              0.528532      0.444852                 0.288799      0.200892                 0.118713       0.0321372                 1.45799             1.458                          0.364868            0.364876                       0.014002                0.000664579                        
[J14          254         2049.43       1           5.11355e-05  0.47865                           0.46506                                0.211721                               0.01359                                  1.458                                              0.364879                                           0.000113964                                                
[J14          256         2050.44       1           5.15389e-05  0.476954                          0.466001                               0.214977                               0.0109532                                1.458                                              0.364886                                           6.97764e-05                                                
[J14          258         2051.33       1           5.19424e-05  0.491841                          0.470933                               0.219173                               0.0209077                                1.45799                                            0.364883                                           0.000297056                                                
[J14          260         2052.2        1           5.23458e-05  0.481393                          0.470269                               0.220387                               0.0111233                                1.45801                                            0.364886                                           0.000146724                                                
[J14          262         2053.06       1           5.27492e-05  0.472098                          0.460898                               0.210487                               0.0111998                                1.45804                                            0.364897                                           0.000113194                                                
[J14          264         2053.97       1           5.31527e-05  0.46879                           0.460983                               0.20721                                0.00780655                               1.45806                                            0.364907                                           6.25189e-05                                                
[J14          266         2054.83       1           5.35561e-05  0.467628                          0.459906                               0.211033                               0.00772148                               1.45809                                            0.364918                                           6.77473e-05                                                
[J14          268         2055.68       1           5.39595e-05  0.476115                          0.46416                                0.212674                               0.0119544                                1.45813                                            0.364903                                           0.000172535                                                
[J15          270         2187.09       1           5.4363e-05  0.498496    0.466623              0.477448      0.436029                 0.228842      0.192495                 0.0210488      0.0305936                 1.45817             1.45819                        0.364887            0.364886                       0.000493412             0.000591477                        
[J15          272         2192.37       1           5.47664e-05  0.501447                          0.467652                               0.218476                               0.0337952                                1.4582                                             0.364886                                           0.000612154                                                
[J15          274         2193.21       1           5.51698e-05  0.47257                           0.462345                               0.213087                               0.0102256                                1.45821                                            0.364884                                           7.09146e-05                                                
[J15          276         2193.97       1           5.55733e-05  0.465863                          0.45254                                0.20482                                0.0133227                                1.45822                                            0.364891                                           0.000226123                                                
[J15          278         2194.84       1           5.59767e-05  0.492513                          0.483778                               0.232099                               0.00873479                               1.45824                                            0.364911                                           0.000192486                                                
[J15          280         2195.66       1           5.63801e-05  0.475154                          0.463084                               0.211409                               0.0120695                                1.45827                                            0.36493                                            9.12007e-05                                                
[J15          282         2196.48       1           5.67836e-05  0.474842                          0.461535                               0.211118                               0.0133073                                1.45828                                            0.364949                                           0.000147091                                                
[J15          284         2197.39       1           5.7187e-05  0.481629                          0.471632                               0.225807                               0.00999677                               1.45828                                            0.364972                                           0.000155675                                                
[J15          286         2198.21       1           5.75905e-05  0.485014                          0.46323                                0.211991                               0.0217841                                1.45828                                            0.365002                                           0.000428808                                                
[J16          288         2329.59       1           5.79939e-05  0.464219    0.460681              0.454652      0.435182                 0.203495      0.191994                 0.00956719     0.0254987                 1.45831             1.45836                        0.365016            0.365025                       6.03251e-05             0.000671507                        
[J16          290         2334.81       1           5.83973e-05  0.481179                          0.471492                               0.221955                               0.00968747                               1.45837                                            0.365033                                           0.000171303                                                
[J16          292         2335.66       1           5.88008e-05  0.455652                          0.449148                               0.197974                               0.00650445                               1.45843                                            0.365056                                           7.55076e-05                                                
[J16          294         2336.46       1           5.92042e-05  0.461974                          0.453542                               0.204277                               0.00843232                               1.45848                                            0.365084                                           6.46089e-05                                                
[J16          296         2337.32       1           5.96076e-05  0.461368                          0.45285                                0.203025                               0.00851755                               1.45852                                            0.365116                                           5.43601e-05                                                
[J16          298         2338.2        1           6.00111e-05  0.489318                          0.480448                               0.230452                               0.00886983                               1.45855                                            0.365131                                           0.000168704                                                
[J16          300         2339.06       1           6.04145e-05  0.475512                          0.459152                               0.210706                               0.01636                                  1.45856                                            0.365141                                           0.000437975                                                
[J     total [#########################################.........] 83.33%
this epoch [#################################.................] 66.67%
       300 iter, 16 epoch / 20 epochs
   0.12492 iters/sec. Estimated time to finish: 0:08:00.306193.
[4A[J16          302         2339.96       1           6.08179e-05  0.466992                          0.455676                               0.205385                               0.0113153                                1.45858                                            0.365127                                           0.000127522                                                
[J16          304         2340.77       1           6.12214e-05  0.463005                          0.446774                               0.196996                               0.0162313                                1.45859                                            0.365091                                           0.000132884                                                
[J17          306         2475.03       1           6.16248e-05  0.598815    0.469459              0.490109      0.431252                 0.251135      0.188315                 0.108706       0.0382075                 1.4586              1.45862                        0.365038            0.365005                       0.0107163               0.000797894                        
[J17          308         2479.22       1           6.20282e-05  0.455945                          0.44772                                0.195329                               0.00822487                               1.45863                                            0.364999                                           5.42207e-05                                                
[J17          310         2480.04       1           6.24317e-05  0.489191                          0.463971                               0.217388                               0.0252202                                1.45865                                            0.36498                                            0.000601711                                                
[J17          312         2480.94       1           6.28351e-05  0.487167                          0.477624                               0.225991                               0.00954327                               1.45867                                            0.364981                                           0.00020276                                                 
[J17          314         2481.83       1           6.32386e-05  0.4634                            0.453011                               0.201386                               0.0103896                                1.4587                                             0.364985                                           0.000112226                                                
[J17          316         2482.77       1           6.3642e-05  0.479817                          0.473505                               0.227997                               0.0063124                                1.45874                                            0.364989                                           0.000217343                                                
[J17          318         2483.62       1           6.40454e-05  0.469495                          0.458019                               0.21048                                0.0114758                                1.45879                                            0.365006                                           0.000123274                                                
[J17          320         2484.39       1           6.44489e-05  0.544482                          0.490005                               0.255007                               0.0544765                                1.4588                                             0.365047                                           0.0102522                                                  
[J17          322         2485.11       1           6.48523e-05  0.455668                          0.448176                               0.195596                               0.00749196                               1.45883                                            0.365072                                           7.02049e-05                                                
[J18          324         2619.11       1           6.52557e-05  0.493877    0.455561              0.467456      0.430382                 0.21576       0.187436                 0.0264208      0.0251785                 1.45886             1.45887                        0.365096            0.365118                       0.00148806              0.000752968                        
[J18          326         2624.29       1           6.56592e-05  0.488941                          0.463058                               0.213192                               0.025883                                 1.45888                                            0.365126                                           0.00143961                                                 
[J18          328         2625.09       1           6.60626e-05  0.483578                          0.462364                               0.212744                               0.0212141                                1.4589                                             0.365154                                           0.000655385                                                
[J18          330         2625.77       1           6.6466e-05  0.51284                           0.477248                               0.24097                                0.0355925                                1.45891                                            0.36518                                            0.0104677                                                  
[J18          332         2626.62       1           6.68695e-05  0.449745                          0.443577                               0.194929                               0.00616804                               1.45895                                            0.365212                                           6.71555e-05                                                
[J18          334         2627.43       1           6.72729e-05  0.445763                          0.438391                               0.188399                               0.00737186                               1.45899                                            0.365249                                           4.78983e-05                                                
[J18          336         2628.25       1           6.76763e-05  0.462676                          0.452373                               0.201658                               0.0103032                                1.45902                                            0.365282                                           8.93476e-05                                                
[J18          338         2629.05       1           6.80798e-05  0.448024                          0.440023                               0.191932                               0.00800134                               1.45906                                            0.365289                                           0.000211461                                                
[J18          340         2629.85       1           6.84832e-05  0.478435                          0.467537                               0.221343                               0.0108987                                1.45912                                            0.365276                                           0.000222535                                                
[J19          342         2761.56       1           6.88867e-05  0.453038    0.461519              0.444617      0.427751                 0.197107      0.185205                 0.00842119     0.0337676                 1.45918             1.45922                        0.365272            0.365286                       0.000127115             0.000693141                        
[J19          344         2765.54       1           6.92901e-05  0.455799                          0.443491                               0.195602                               0.0123082                                1.45923                                            0.365298                                           6.67644e-05                                                
[J19          346         2766.38       1           6.96935e-05  0.449527                          0.440732                               0.193504                               0.00879454                               1.45925                                            0.365346                                           6.79316e-05                                                
[J19          348         2767.19       1           7.0097e-05  0.45966                           0.449515                               0.200609                               0.0101454                                1.45926                                            0.365391                                           0.000224381                                                
[J19          350         2768          1           7.05004e-05  0.457232                          0.449251                               0.199976                               0.00798107                               1.45928                                            0.365452                                           0.000126606                                                
[J19          352         2768.73       1           7.09038e-05  0.456751                          0.447388                               0.195876                               0.00936254                               1.45931                                            0.365482                                           0.000163424                                                
[J19          354         2769.55       1           7.13073e-05  0.482902                          0.460046                               0.211413                               0.0228556                                1.45933                                            0.365476                                           0.0014895                                                  
[J19          356         2770.43       1           7.17107e-05  0.461482                          0.447169                               0.199434                               0.0143133                                1.45934                                            0.365443                                           0.000160782                                                
[J19          358         2771.27       1           7.21141e-05  0.482681                          0.46038                                0.212302                               0.0223015                                1.45935                                            0.365409                                           0.000639716                                                
[J20          360         2905.69       1           7.25176e-05  0.459434    0.454121              0.444656      0.426335                 0.198537      0.184545                 0.0147778      0.0277861                 1.45936             1.45937                        0.365383            0.365373                       0.000561309             0.000695545                        
[J/home/katsuki/tool/espnet/espnet/nets/pytorch_backend/transformer/plot.py:28: UserWarning: tight_layout : falling back to Agg renderer
  fig.tight_layout()
/home/katsuki/tool/espnet/espnet/nets/pytorch_backend/e2e_tts_transformer.py:144: UserWarning: tight_layout : falling back to Agg renderer
  fig.tight_layout()
# Accounting: time=2930 threads=1
# Finished at Wed Sep 25 01:31:53 EDT 2019 with status 0
